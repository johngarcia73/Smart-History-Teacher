from nltk.tokenize import word_tokenize, sent_tokenize
import nltk
nltk.download('punkt_tab')
# Prueba de tokenizaci칩n en espa침ol
texto = "Hola mundo. Esto es una prueba."
print("Tokenizaci칩n de oraciones:", sent_tokenize(texto, language='spanish'))
print("Tokenizaci칩n de palabras:", word_tokenize(texto, language='spanish'))